import os
import sys
import subprocess
from pathlib import Path
from dotenv import load_dotenv
import logging
from typing import List, Optional
from pydantic import BaseModel
from openai import OpenAI
import instructor

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

load_dotenv()
class IssueCode(BaseModel):
    file_path: str
    line_number: Optional[int]
    severity: str
    message: str
    suggestion: str
    category: str

class AnalysisResult(BaseModel):
    issues: List[IssueCode]
    passed: bool
    summary: str
    code_quality_score: int

CODE_CHECK_CONTENT = '''
import os
import sys
from typing import List, Optional
import instructor
from openai import OpenAI
from pydantic import BaseModel
import subprocess
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class IssueCode(BaseModel):
    file_path: str
    line_number: Optional[int]
    severity: str
    message: str
    suggestion: str
    category: str

class AnalysisResult(BaseModel):
    issues: List[IssueCode]
    passed: bool
    summary: str
    code_quality_score: int

def get_files_to_analyze():
    """Get only new and staged files that actually exist"""
    
    files_to_check = set()  # Using set to avoid duplicates
    repo_path = os.getcwd()
    
    try:
        # Get staged files
        staged = subprocess.run(
            ['git', 'diff', '--cached', '--name-only'],
            capture_output=True,
            text=True
        )
        staged_files = staged.stdout.splitlines()
        
        # Get untracked (new) files
        untracked = subprocess.run(
            ['git', 'ls-files', '--others', '--exclude-standard'],
            capture_output=True,
            text=True
        )
        untracked_files = untracked.stdout.splitlines()
        
        # Combine and filter files
        all_files = set(staged_files + untracked_files)
        
        # Filter by extension and existence
        valid_files = []
        for file in all_files:
            full_path = os.path.join(repo_path, file)
            if (file.endswith(('.py', '.ts', '.mjs')) and 
                os.path.exists(full_path) and 
                os.path.isfile(full_path)):
                valid_files.append(file)
        
        if not valid_files:
            print("\nüí° No new or staged files found to analyze")
            print("   To analyze files:")
            print("   1. Create new .py, .ts or .mjs files")
            print("   2. Or modify existing files and run 'git add'")
            
        return valid_files
        
    except Exception as e:
        print(f"\n‚ùå Error getting files: {e}")
        return []

def analyze_file(client, file_path: str) -> AnalysisResult:
    """Analyzes an individual file"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    messages = [
        {"role": "system", "content": """Please analyze this code in detail and provide specific feedback for:
1. Clean code principles:
- Variable and function names
- Structure and organization
- Comments and documentation
- Code duplication

2. Security best practices:
- Input validation
- Sensitive data handling
- Common vulnerabilities

3. Performance considerations:
- Algorithm optimization
- Memory usage
- Time complexity

4. Type safety:
- Correct type usage
- Type hints
- Type validation

5. Error handling:
- Appropriate try/catch
- Descriptive error messages
- Logging

For each issue found, provide:
- Severity (high/medium/low)
- Clear problem message
- Specific suggestion for improvement
- Problem category
- Specific line of code when possible

Assign a code quality score from 0 to 100."""},
        {"role": "user", "content": f"File {file_path}:\n{content}"}
    ]

    return client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        response_model=AnalysisResult
    )

def main():
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("‚ö†Ô∏è Error: OPENAI_API_KEY not configured in .env file")
        sys.exit(1)

    client = instructor.from_openai(OpenAI())
    files_to_check = get_files_to_analyze()

    if not files_to_check:
        print("No files found to analyze")
        sys.exit(0)

    total_issues = []
    all_scores = []
    failed = False

    print("\nüîç Starting code analysis...")
    print("=" * 80)

    for file_path in files_to_check:
        print(f"\nüìù Analyzing {file_path}...")
        try:
            result = analyze_file(client, file_path)
            all_scores.append(result.code_quality_score)
            
            print(f"\nüìä Quality Score: {result.code_quality_score}/100")
            
            if not result.passed or result.code_quality_score < 70:
                failed = True
                total_issues.extend(result.issues)
                print(f"\n‚ö†Ô∏è Problems encountered in {file_path}:")
                print(f"Summary: {result.summary}")
                
                issues_by_category = {}
                for issue in result.issues:
                    if issue.category not in issues_by_category:
                        issues_by_category[issue.category] = []
                    issues_by_category[issue.category].append(issue)
                
                for category, issues in issues_by_category.items():
                    print(f"\nüìå {category.upper()}:")
                    for issue in issues:
                        print(f"\n  Severity: {issue.severity}")
                        print(f"  Problem: {issue.message}")
                        print(f"  Advice: {issue.suggestion}")
                        if issue.line_number:
                            print(f"  Line: {issue.line_number}")
                        print("  " + "-" * 40)

        except Exception as e:
            print(f"‚ùå Error parsing {file_path}: {str(e)}")
            sys.exit(1)

    print("\n" + "=" * 80)
    if len(all_scores) > 0:
        avg_score = sum(all_scores) / len(all_scores)
        print(f"\nüìä Average project score: {avg_score:.2f}/100")

    if failed:
        print("\n‚ùå Review failed. Please fix the issues before committing.")
        sys.exit(1)
    else:
        print("\n‚úÖ All files passed review!")
        sys.exit(0)

if __name__ == "__main__":
    main()
'''

def get_files_to_analyze():
    """
    Retrieve new and staged files for analysis.

    Returns:
        List[str]: A list of valid file paths that match supported extensions (.py, .ts, .mjs, etc.).
    Raises:
        FileNotFoundError: If the repository path is invalid or files cannot be accessed.
        subprocess.CalledProcessError: If there are issues running git commands.
    """
    files_to_check = set()  # Using set to avoid duplicates
    repo_path = os.getcwd()
    
    try:
        # Get staged files
        staged = subprocess.run(
            ['git', 'diff', '--cached', '--name-only'],
            capture_output=True,
            text=True
        )
        staged_files = staged.stdout.splitlines()
        
        # Get untracked (new) files
        untracked = subprocess.run(
            ['git', 'ls-files', '--others', '--exclude-standard'],
            capture_output=True,
            text=True
        )
        untracked_files = untracked.stdout.splitlines()
        
        # Combine and filter files
        all_files = set(staged_files + untracked_files)
        
        # Filter by extension and existence
        valid_files = []
        for file in all_files:
            full_path = os.path.join(repo_path, file)
            if (file.endswith(('.py', '.ts', '.mjs', '.js', '.sql', '.css', '.html', '.ipynb')) and 
                os.path.exists(full_path) and 
                os.path.isfile(full_path)):
                valid_files.append(file)
        
        if not valid_files:
            print("\nüí° No new or staged files found to analyze")
            print(" To analyze files:")
            print(" 1. Create new .py, .ts, .mjs, .js, .sql, .css, .html, or .ipynb files")
            print(" 2. Or modify existing files and do 'git add'")
            
        return valid_files
        
    except Exception as e:
        print(f"\n‚ùå Error getting files: {e}")
        return []

def analyze_file(client, file_path: str) -> AnalysisResult:
    """
    Analyze a specific file for code quality, security, and performance issues.

    Args:
        client: The OpenAI client used for analysis.
        file_path (str): Path to the file to be analyzed.

    Returns:
        AnalysisResult: The result of the analysis, including detected issues and a quality score.

    Raises:
        FileNotFoundError: If the file does not exist or cannot be read.
        Exception: For general issues during the analysis.
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    messages = [
        {"role": "system", "content": """Analyze this code closely for:
        1. Clean code principles
        2. Security best practices
        3. Performance considerations
        4. Type safety
        5. Error handling"""},
        {"role": "user", "content": f"File {file_path}:\n{content}"}
    ]

    return client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        response_model=AnalysisResult
    )

def analyze_setup_files(repo_path: str, client) -> bool:
    """Scan configuration files before installing them"""
    setup_files = [
        ('pre_commit_code_check.py', CODE_CHECK_CONTENT),
        ('setup_code_review.py', Path(__file__).read_text())
    ]
    
    print("\nüîç Parsing configuration files...")
    print("=" * 80)
    
    all_passed = True
    for filename, content in setup_files:
        print(f"\nüìù Analyzing {filename}...")
        
        # Create temporary file for analysis
        temp_path = os.path.join(repo_path, filename)
        with open(temp_path, 'w') as f:
            f.write(content)
            
        try:
            result = analyze_file(client, temp_path)
            print(f"\nüìä Quality Score: {result.code_quality_score}/100")
            
            if not result.passed or result.code_quality_score < 70:
                all_passed = False
                print(f"\n‚ö†Ô∏è Problems encountered in {filename}:")
                print(f"Summary: {result.summary}")
                
                issues_by_category = {}
                for issue in result.issues:
                    if issue.category not in issues_by_category:
                        issues_by_category[issue.category] = []
                    issues_by_category[issue.category].append(issue)
                
                for category, issues in issues_by_category.items():
                    print(f"\nüìå {category.upper()}:")
                    for issue in issues:
                        print(f"\n  Severity: {issue.severity}")
                        print(f"  Problem: {issue.message}")
                        print(f"  Advice: {issue.suggestion}")
                        if issue.line_number:
                            print(f"  Line: {issue.line_number}")
                        print("  " + "-" * 40)
            
        except Exception as e:
            print(f"‚ùå Error parsing {filename}: {str(e)}")
            all_passed = False
            
        os.remove(temp_path)  # Clean up temporary file
    
    return all_passed

def create_files(repo_path):
    with open(os.path.join(repo_path, 'pre_commit_code_check.py'), 'w') as f:
        f.write(CODE_CHECK_CONTENT.strip())
    
    precommit_config_content = '''
repos:
-   repo: local
    hooks:
    -   id: code-review
        name: Code Review AI
        entry: python pre_commit_code_check.py
        language: python
        types: [python, typescript, javascript, sql, css, html]
        additional_dependencies: []
        files: \.(py|ts|mjs|js|sql|css|html|ipynb)$
        pass_filenames: false
'''

    with open(os.path.join(repo_path, '.pre-commit-config.yaml'), 'w') as f:
        f.write(precommit_config_content.strip())
    
    requirements_content = '''
instructor>=1.6.4
openai>=1.12.0
pydantic>=2.0.0
pre-commit
python-dotenv
'''
    with open(os.path.join(repo_path, 'requirements.txt'), 'w') as f:
        f.write(requirements_content.strip())
    
    # Create .gitignore
    gitignore_content = '''
.env
__pycache__/
*.pyc
.venv/
'''
    with open(os.path.join(repo_path, '.gitignore'), 'w') as f:
        f.write(gitignore_content.strip())

def analyze_repository(repo_path: str):
    client = instructor.from_openai(OpenAI())
    files_to_check = get_files_to_analyze()

    if not files_to_check:
        print("\n‚ö†Ô∏è No files found to scan")
        print("üí° Scan includes:")
        print(" 1. New files (untracked)")
        print(" 2. Modified files (unstaged)")
        print(" 3. Files staged for commit")
        print(" Files only: .py, .ts, .mjs")
        return

    total_issues = []
    all_scores = []

    print("\nüîç Starting code analysis...")
    print("=" * 80)

    for file_path in files_to_check:
        full_path = os.path.join(repo_path, file_path)
        
        if not os.path.exists(full_path):
            print(f"\n‚ö†Ô∏è The file {file_path} does not exist in the repository")
            continue

        # Get file status
        status = ""
        if file_path in subprocess.run(['git', 'diff', '--cached', '--name-only'], 
                                     capture_output=True, text=True).stdout.splitlines():
            status = "[Staged]"
        elif file_path in subprocess.run(['git', 'ls-files', '--others', '--exclude-standard'], 
                                       capture_output=True, text=True).stdout.splitlines():
            status = "[New]"
        else:
            status = "[Modified]"
            
        print(f"\nüìù Analyzing {file_path} {status}...")
        
        try:
            result = analyze_file(client, full_path)
            all_scores.append(result.code_quality_score)
            
            print(f"\nüìä Quality Score: {result.code_quality_score}/100")
            if not result.passed or result.code_quality_score < 70:
                total_issues.extend(result.issues)
                print(f"\n‚ö†Ô∏è Problems encountered in {file_path}:")
                print(f"Summary: {result.summary}")
                
                issues_by_category = {}
                for issue in result.issues:
                    if issue.category not in issues_by_category:
                        issues_by_category[issue.category] = []
                    issues_by_category[issue.category].append(issue)
                
                for category, issues in issues_by_category.items():
                    print(f"\nüìå {category.upper()}:")
                    for issue in issues:
                        print(f"\n  Severity: {issue.severity}")
                        print(f"  Problem: {issue.message}")
                        print(f"  Advice: {issue.suggestion}")
                        if issue.line_number:
                            print(f"  Line: {issue.line_number}")
                        print("  " + "-" * 40)

        except Exception as e:
            print(f"‚ùå Error parsing {file_path}: {str(e)}")

    if all_scores:
        avg_score = sum(all_scores) / len(all_scores)
        print(f"\nüìä Average project score: {avg_score:.2f}/100")

def setup_repository():
    """
    Configure the repository for pre-commit analysis.

    Steps:
        1. Validate the repository path
        2. Initialize Git (if not already initialized)
        3. Create configuration files
        4. Install dependencies and pre-commit hook

    Raises:
        FileNotFoundError: If specified repository path is invalid
        Exception: If errors occur during setup
    """

    print("üîç Enter the repository path you want to analyze")
    print("(Press Enter to use current directory)")
    
    repo_path = input("Path: ").strip()
    
    if not repo_path:
        repo_path = os.getcwd()
    
    if not os.path.exists(repo_path):   
        print("‚ùå Specified path does not exist")
        sys.exit(1)

    print(f"\nüìÇSelected repository: {repo_path}")

    if not os.path.exists(os.path.join(repo_path, '.git')):
        print("‚ö†Ô∏è Initializing git repository...")
        subprocess.run(['git', 'init'], cwd=repo_path)
        subprocess.run(['git', 'checkout', '-b', 'main'], cwd=repo_path)

    print("\nüìù Creating configuration files...")
    create_files(repo_path)

    print("\nüì¶ Installing dependencies...")
    subprocess.run(['pip', 'install', '-r', 'requirements.txt'], cwd=repo_path)

    print("\n‚öôÔ∏è Setting up pre-commit...")
    subprocess.run(['pre-commit', 'install'], cwd=repo_path)

    env_path = os.path.join(repo_path, '.env')
    if not os.path.exists(env_path):
        api_key = input("\nüîë Enter your OpenAI API key: ").strip()
        with open(env_path, 'w') as f:
            f.write(f'OPENAI_API_KEY={api_key}\n')

    print("\n‚úÖ Setup complete!")
    print("\nüí° Pre-commit hook installed and ready to:")
    print(" 1. Scan new files (.py, .ts, .mjs) when using 'git add'")
    print(" 2. Review code before each commit")
    print("\nUsage:")
    print(" 1. Modify or create new files")
    print(" 2. Use 'git add' on files to commit")
    print(" 3. Scanning runs automatically on 'git commit'")

if __name__ == "__main__":
    setup_repository()
